{
  "summary": "This paper introduces SCOTCH, a novel structure learning method that combines neural stochastic differential equations (SDEs) with variational inference to discover causal relationships in continuous-time temporal data. The approach can handle irregularly sampled time series and provides theoretical guarantees for structural identifiability and consistency. Experiments on synthetic and real-world datasets demonstrate improved performance over discrete-time baselines.",
  "strengths": [
    "Strong theoretical contributions including proofs of structural identifiability for SDEs under diagonal diffusion assumptions and consistency guarantees for the variational formulation in the infinite data limit",
    "Novel continuous-time formulation that naturally handles irregular sampling and addresses limitations of discrete-time methods, with clear motivation through a bimodal failure case showing ODE-based methods cannot handle multimodal trajectories",
    "Comprehensive experimental evaluation on both synthetic (Lorenz-96, Glycolysis) and real-world datasets (DREAM3, Netsim) with consistent improvements over relevant baselines including VARLiNGaM, PCMCI+, CUTS, Rhino, and NGM",
    "Well-written paper with clear explanation of the latent SDE formulation, variational inference framework, and connection to existing discrete-time methods like Rhino",
    "Thorough appendix with detailed proofs, implementation details, hyperparameters, and additional experimental results"
  ],
  "weaknesses": [
    "The diagonal diffusion assumption (Assumption 2) is quite restrictive and may limit applicability to real-world systems where cross-dimensional noise correlations exist. The paper acknowledges this but provides limited discussion on when this assumption is reasonable",
    "Cannot handle instantaneous effects, which is explicitly mentioned as a limitation and shown to be important in datasets like Netsim where Rhino (with instantaneous effects) performs better",
    "Computational scalability concerns: the method scales linearly with series length and requires solving SDEs during training, which is computationally expensive. Limited discussion on computational complexity and runtime comparisons with baselines",
    "The improvement over NGM on some datasets (e.g., Lorenz with p=0.6) is modest, and the advantage over Rhino on Netsim is minimal, raising questions about when the continuous-time formulation provides substantial benefits",
    "Limited evaluation on truly large-scale or high-dimensional systems. DREAM3 has 100 dimensions but only 21 time points, which may not fully stress-test the method's scalability"
  ],
  "clarity_score": 8,
  "novelty_score": 8,
  "technical_quality_score": 8,
  "experimental_rigor_score": 7,
  "overall_score": 7,
  "confidence": 4,
  "recommendation": "Accept",
  "detailed_comments": "This is a solid paper that makes meaningful contributions to causal structure learning in continuous time. The theoretical results on identifiability are valuable and the experimental validation is reasonably comprehensive. The main concerns are: (1) the restrictive diagonal diffusion assumption needs more justification, (2) inability to handle instantaneous effects limits practical applicability, and (3) computational costs and scalability could be better addressed. Despite these limitations, the paper represents a clear advance over existing methods and the continuous-time formulation opens interesting avenues for future work. The writing quality is generally high, though some sections (especially the theory) are dense. Minor improvements could include more discussion of when the method is expected to outperform discrete alternatives and clearer guidance on hyperparameter selection.",
  "paper_id": "V1GM9xDvIY",
  "version": "latest",
  "run_id": 0,
  "model_type": "Anthropic",
  "success": true,
  "soundness": 8,
  "presentation": 8,
  "contribution": 8,
  "rating": 7
}