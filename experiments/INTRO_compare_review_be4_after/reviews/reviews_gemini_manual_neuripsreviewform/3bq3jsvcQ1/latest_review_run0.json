{
  "summary": "This paper introduces \"Step-Back Prompting,\" a few-shot technique where an LLM is prompted to first generate a more abstract, high-level question (e.g., about general principles or broader concepts) from an original, specific question. The LLM then answers this \"step-back\" question to retrieve guiding facts or principles. Finally, it uses this retrieved information to reason about and answer the original, specific question. The authors show this method, sometimes combined with RAG, improves performance for models like PaLM-2L and GPT-4 on reasoning tasks in STEM, knowledge QA, and multi-hop reasoning.",
  "strengths": [
    "The proposed \"Step-Back Prompting\" method is simple, intuitive, and requires only a few-shot exemplars to implement.",
    "The technique demonstrates substantial empirical gains over standard and Chain-of-Thought (CoT) prompting on several challenging reasoning datasets, particularly TimeQA and MMLU.",
    "The error analysis (Figures 4 & 5) is thorough and insightfully identifies the \"Reasoning\" step, not the \"Abstraction\" step, as the primary bottleneck, reinforcing the authors' hypothesis that abstraction is easy for LLMs to perform.",
    "The paper astutely identifies that using a generalized \"step-back\" query for Retrieval-Augmented Generation (RAG) is more effective than using the original, specific query, as shown in the TimeQA results (Table 2)."
  ],
  "weaknesses": [
    "The paper's primary conceptual claim—that the method is \"abstraction\" rather than \"decomposition\"—is weakly defended and appears to be a semantic distinction without a strong functional difference from prior work.",
    "The paper critically fails to compare against key decomposition-based prompting methods like Least-to-Most (Zhou et al., 2022) or Decomposed Prompting (Khot et al., 2022) in the main results, despite these being the most relevant SOTA baselines.",
    "The outlier result on GSM8K (Table 4), where Step-Back provides no significant benefit over CoT, undermines the generality of the method's contribution to \"reasoning\" and suggests its primary benefit may be limited to knowledge-intensive or fact-grounding tasks.",
    "The evaluation methodology (Section 3.3) relies on PaLM-2L to score the correctness of its own family's (PaLM-2L) outputs, creating a potential conflict of interest and source of bias.",
    "The distinction between the MMLU implementation (retrieving internal principles) and the QA implementation (retrieving external facts via RAG) is significant, bundling two different use cases under a single \"abstraction\" name."
  ],
  "questions": [
    "The core claim rests on \"abstraction\" being distinct from \"decomposition.\" Can you provide a more rigorous, operationalized definition and demonstrate a task where Step-Back succeeds but a method like Decomposed Prompting (Khot et al., 2022) fails (and vice-versa), to prove they are functionally different?",
    "Why were decomposition baselines (e.g., Decomposed Prompting, Least-to-Most) omitted from the main experiments on MuSiQue, StrategyQA, and TimeQA, given their direct relevance and SOTA performance on such multi-hop tasks? Please provide these crucial comparison numbers.",
    "The gains on GSM8K are non-existent compared to CoT. Does this imply Step-Back Prompting is primarily a knowledge-retrieval enhancement (i.e., query reformulation) rather than a reasoning enhancement (i.e., superior logical structuring)?",
    "The evaluation relies on PaLM-2L to judge PaLM-2L outputs. Have you validated these results using an independent judge (e.g., GPT-4 or human annotators) to rule out model-family-specific evaluation bias?",
    "Figure 5 shows RAG failures (0.45) are a major error source. Does this mean the generalized step-back query, while better than the original, still often retrieves incorrect or irrelevant documents? How does this compare to RAG failure rates for the original queries?"
  ],
  "limitations_and_societal_impact": "The authors address limitations in the Discussion (Section 7), noting that abstraction is not always necessary or possible (e.g., for simple factoid questions). They also correctly identify, via error analysis, that the post-abstraction \"Reasoning\" step remains the key bottleneck. However, the paper does not discuss societal impacts. A potential negative impact is that this method could be used to \"abstract\" a sensitive, specific query (e.g., about a private individual) into a broader query (e.g., \"what is this person's entire employment history?\"), which might bypass privacy filters focused on specific, narrow queries. The authors should consider this \"abstraction attack\" vector.",
  "soundness": 2,
  "presentation": 3,
  "contribution": 2,
  "overall_score": 4,
  "confidence": 5,
  "rating": 4,
  "paper_id": "3bq3jsvcQ1",
  "version": "latest",
  "run_id": 0,
  "model_type": "gemini_manual_CriticalNeurIPS",
  "success": true,
  "source": "manual_gemini_ui"
}