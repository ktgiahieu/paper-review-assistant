{
  "summary": "This paper introduces a hierarchical graph generative model that builds graphs by iteratively reversing a graph coarsening process. Starting from a single node, the model progressively expands nodes into clusters and uses a denoising diffusion model to refine the resulting locally dense graph structure. This refinement is parameterized by a novel 'Local PPGN' graph neural network, designed to be expressive in dense local regions while remaining computationally efficient. The method achieves strong scalability, generating un-attributed graphs with over 5000 nodes, and uniquely demonstrates the ability to extrapolate and generate valid graphs of sizes significantly larger than those seen during training.",
  "strengths": [
    "The core conceptual contribution of iterative local expansion, framed as the learned inverse of a principled spectral graph coarsening process, is novel and elegant.",
    "The model is the first to demonstrate successful extrapolation (Figure 3), generating valid graphs of sizes far outside the training distribution, a significant step forward for graph generative models.",
    "The method scales effectively to large, real-world graphs (5000+ nodes), outperforming many baselines on structural similarity metrics (Table 2).",
    "The proposed 'Local PPGN' architecture is a well-motivated and novel GNN variant that balances local expressivity (akin to PPGN) with global scalability (akin to MPNNs).",
    "The methodology is a strong synthesis of modern techniques, including denoising diffusion, spectral conditioning (via SignNet), and expressive GNNs."
  ],
  "weaknesses": [
    "The model, as presented, only generates un-attributed graphs. Its inability to handle node or edge features is a major limitation that is not discussed, precluding its use for standard, high-impact tasks like molecular generation (e.g., QM9, ZINC).",
    "The experimental comparison is incomplete. It omits critical, state-of-the-art scalable and hierarchical baselines (e.g., GraphGen, HiGen, Unpooling-GAN), making the claims of superior scalability and performance unsubstantiated.",
    "The 'Ours (one-shot)' baseline is poorly explained. Its superior performance on the SBM dataset (Table 1) calls into question the universal benefit of the iterative expansion process.",
    "The empirical runtime (Fig 6/14) is slower than BiGG, which contradicts the paper's own theoretical complexity analysis (Appendix 13) claiming an asymptotically faster O(n+m) runtime.",
    "The SBM results are weaker than those of other models, suggesting the method may struggle with graphs whose primary structure is not well-captured by spectral coarsening."
  ],
  "questions": [
    "The inability to handle node/edge attributes is a significant restriction. Could the authors formally discuss how the framework, particularly the coarsening (Def 3) and expansion (Def 1) steps, would be extended to manage features? This seems highly non-trivial.",
    "The scalability claims are not fully supported without comparing to other highly scalable baselines like GraphGen or hierarchical models like HiGen. A thorough comparison against these methods is needed to validate the paper's scalability contributions.",
    "Please clarify the 'Ours (one-shot)' baseline. What is its exact architecture, and why does it outperform the full iterative model on the SBM dataset (Table 1)?",
    "Your theoretical complexity in Appendix 13 is O(n+m), which is asymptotically superior to BiGG's O((n+m)log n). Why is your method empirically slower in Figure 6/14? What constants or hidden factors dominate?",
    "Regarding the excellent extrapolation results, how much of this is an inductive bias of the iterative architecture (which resembles an RNN) versus a learned property? For instance, would a simpler iterative model like GraphRNN also extrapolate, even if its sample quality is lower?"
  ],
  "limitations_and_societal_impact": "The authors have not included a limitations or societal impact section. This is a critical omission. The paper's primary and most significant limitation is that the proposed method can only generate *un-attributed* graphs. This makes it unsuitable for the majority of real-world applications cited in the introduction, such as drug discovery or protein design, which fundamentally rely on node and edge features (e.g., atom types, bond types). This limitation must be explicitly and clearly stated in the main paper. Furthermore, the authors should add a standard disclaimer regarding the potential misuse of generative models, while noting no immediate negative societal impacts.",
  "soundness": 3,
  "presentation": 4,
  "contribution": 3,
  "overall_score": 6,
  "confidence": 5,
  "rating": 6,
  "paper_id": "2XkTz7gdpc",
  "version": "latest",
  "run_id": 0,
  "model_type": "gemini_manual_CriticalNeurIPS",
  "success": true,
  "source": "manual_gemini_ui"
}