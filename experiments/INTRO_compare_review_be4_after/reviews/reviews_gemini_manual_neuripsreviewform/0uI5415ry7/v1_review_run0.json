{
  "summary": "This paper investigates the optimization difficulties of Transformer models by proposing a simplified proxy: a shallow, linear self-attention network (without softmax) trained on synthetic linear regression tasks. The authors demonstrate empirically that this simplified model reproduces several 'distinctive features' of Transformer optimization reported in prior work, such as the superiority of Adam over SGD, heavy-tailed gradient noise, and ill-conditioning. The paper then uses this model to perform controlled experiments, suggesting that data heavy-tailedness and network depth (in this linear setting) exacerbate these phenomena.",
  "strengths": [
    "The goal of finding a minimal, tractable model to understand complex optimization dynamics is highly valuable and follows a strong tradition in physics-style theoretical machine learning.",
    "The paper clearly synthesizes a set of well-defined empirical phenomena from recent literature (e.g., Adam > SGD, heavy-tailed noise, ill-conditioning) as a target for explanation.",
    "The controlled experiments in Section 4, which ablate the effects of data distribution and layer depth on these phenomena, are insightful within the context of the proposed toy model.",
    "The connection drawn between the in-context learning (ICL) setup (linear regression) and broader transformer optimization phenomena is novel."
  ],
  "weaknesses": [
    "The paper's central claim—that a shallow linear model on linear regression is a 'valuable, realistic abstraction' for Transformer optimization—is severely under-supported.",
    "The empirical evidence is based entirely on a single, synthetic linear regression task, with key non-linearities (softmax) and components (MLPs, LayerNorm) of full Transformers explicitly removed.",
    "The paper fails to provide a direct empirical bridge; it compares its new results on the toy task to prior published results on real tasks, rather than testing both full and toy models in a unified setting.",
    "It is an unstated and unsupported assumption that the mechanisms causing (e.g.) ill-conditioning in this simple linear model are the same as those in deep, non-linear models trained on complex language data.",
    "The justification for removing the softmax (Sec 3.1) is circular: the linear model is chosen because it performs well on the linear task, which was chosen to suit the linear model.",
    "The analysis of 'depth' (Sec 4.2) is potentially misleading, as increasing from L=2 to L=8 in this linear model is not a convincing proxy for the challenges of training truly deep (e.g., L=48+) non-linear Transformers."
  ],
  "questions": [
    "How do these results change if the softmax non-linearity is re-introduced, even on the same linear regression task? Does the linear model mask or exaggerate the optimization phenomena?",
    "Could the authors provide a 'minimal-pair' experiment: train both a full (e.g., 2-layer) GPT-style model and your linear model on the same synthetic task? This would isolate the effect of the non-linearities.",
    "Conversely, can you demonstrate that a full Transformer on a real task (e.g., PTB) fails to train with SGD, while a linear-attention-only model on the same data also fails similarly?",
    "Much of the difficulty in training transformers is attributed to the interaction between residual connections and Layer Normalization. How can a model that omits MLPs and LayerNorm be a realistic proxy for these specific, well-known training instabilities?",
    "The paper argues (Sec 2.2) that heavy-tailed noise may not be the full picture, citing Kunstner et al. (2023). Your own analysis in Sec 4.1 also finds a disconnect. What is your concrete alternative hypothesis for why Adam > SGD, if not noise?"
  ],
  "limitations_and_societal_impact": "The paper's primary limitation, which is not adequately addressed, is the vast generalization gap between its toy model (linear attention on linear regression) and the complex, non-linear Transformers on real-world tasks it claims to abstract. The authors should explicitly and prominently state that their findings are, at present, confined to this synthetic ICL-like setting and that the 'realistic' nature of the proxy is a hypothesis, not an empirically validated fact. Societal impacts are not discussed, which is acceptable given the theoretical nature of the work.",
  "soundness": 2,
  "presentation": 4,
  "contribution": 2,
  "overall_score": 4,
  "confidence": 5,
  "rating": 4,
  "paper_id": "0uI5415ry7",
  "version": "v1",
  "run_id": 0,
  "model_type": "gemini_manual_CriticalNeurIPS",
  "success": true,
  "source": "manual_gemini_ui"
}