{
  "summary": "This paper addresses the selective labels problem in machine learning, where outcomes are only observed following a human decision (e.g., a medical test). The authors propose a Bayesian model that jointly models the outcome risk and the testing decision, accounting for unobservable confounders. To stabilize this ill-posed problem, they introduce two domain-specific constraints: a 'prevalence constraint' (knowing the overall outcome rate) and an 'expertise constraint' (assuming some features only affect testing via their effect on risk). Synthetic experiments and a real-world case study on breast cancer risk prediction show that these constraints improve parameter precision and accuracy, notably correcting a spurious age-risk relationship that models without the prevalence constraint learn.",
  "strengths": [
    "The paper tackles a critical and prevalent problem in applied machine learning, particularly in high-stakes domains like healthcare.",
    "The use of a prevalence constraint is a simple, practical, and powerful idea for regularizing models in selective label settings.",
    "The case study on breast cancer risk is executed very well, with a comprehensive set of validations (Sec 5.2) that test the model's different components (inferred risk, unobservables, and parameters).",
    "Figure 4 provides a clear and compelling demonstration of the method's value, showing how the prevalence constraint corrects a spurious and misleading age trend learned by the unconstrained model.",
    "The paper is exceptionally well-written and clearly structured, with high-quality figures that effectively communicate the key results."
  ],
  "weaknesses": [
    "The paper's core methodological limitation is the non-identifiability between the risk-testing coefficient (α) and the unobservable variance (σ²), which the authors acknowledge in the appendix but resolve in the main experiment by fixing α=1. This is a strong, unsupported assumption that directly impacts the interpretation and magnitude of all inferred parameters, especially β_Δ (suboptimality) and σ² (importance of unobservables).",
    "The 'expertise constraint' is conceptually identical to an 'exclusion restriction' from the econometric literature on sample selection models. The paper fails to engage with this vast literature, incorrectly framing the constraint as a novel contribution and missing a deep discussion on identification.",
    "The primary theoretical contribution (Proposition 2) is a direct and well-known consequence of the law of total variance (Var(A) = E[Var(A|B)] + Var(E[A|B])), offering no new insight into the model's identification or statistical properties.",
    "The choice of a Uniform distribution for the unobservables is non-standard and justified primarily by computational convenience. The robustness check against a Normal distribution (Fig 11) is run on a 1/8 subset of the data, which is not a direct or fair comparison to the full-dataset Uniform model."
  ],
  "questions": [
    "The non-identification of α and σ is a critical issue, and fixing α=1 is a very strong assumption. Can you provide a more robust justification for this choice, or else conduct a sensitivity analysis showing how the key findings (e.g., the β_Δ coefficients) change as α is varied across a plausible range?",
    "Could you please move the discussion of the α-σ non-identification from the appendix (Sec 10) to the main model description (Sec 2 or 3)? This is a core property of the model, not a minor implementation detail.",
    "Please explicitly connect your 'expertise constraint' to the 'exclusion restriction' concept in the Heckman sample selection literature. How do you see your constraint differing from, or improving upon, traditional exclusion restrictions?",
    "For the robustness check against Normal noise (Fig 11-12), could you provide a true apples-to-apples comparison by re-running the main Uniform model on the *same* 1/8th data subset? This would clarify if the observed differences are due to the noise distribution or the dataset size."
  ],
  "limitations_and_societal_impact": "The authors discuss societal impact in the context of improving healthcare models and reducing bias. This is well-handled. However, they significantly downplay the primary limitation of their model: the non-identifiability of α and σ, which is relegated to the appendix. This is a crucial limitation that must be discussed in the main paper, as it directly impacts the interpretability of the model's key parameters. Furthermore, they should add a discussion on the failure mode where the *domain constraints themselves are wrong*. If a practitioner uses an incorrect prevalence rate or a faulty 'expertise' assumption, this model will produce confidently incorrect results. This 'garbage-in, garbage-out' risk is a significant practical limitation that needs to be explicitly stated.",
  "soundness": 3,
  "presentation": 4,
  "contribution": 3,
  "overall_score": 7,
  "confidence": 5,
  "rating": 7,
  "paper_id": "1mNFsbvo2P",
  "version": "v1",
  "run_id": 0,
  "model_type": "gemini_manual_CriticalNeurIPS",
  "success": true,
  "source": "manual_gemini_ui"
}